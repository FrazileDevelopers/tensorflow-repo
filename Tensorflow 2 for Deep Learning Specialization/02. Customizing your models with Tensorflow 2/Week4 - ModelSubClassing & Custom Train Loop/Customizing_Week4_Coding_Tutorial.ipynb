{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Customizing_Week4_Coding Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8V-dWfuU7MLO",
        "VETT8KFC7MLY",
        "omOPHxfJ7MLi",
        "4AXpmrZ-7MLo",
        "H29iRg5l7MLx",
        "HTleeosW7ML4",
        "KTEaudvN7ML8",
        "-ryLItfi7MMB",
        "myUlJq2_7MME",
        "tuk_pQ7A7MMI",
        "1V7P3raP7MMN",
        "FWtoHyZK7MMT",
        "xzeCqC697MMV",
        "IQWvJS8y7MMZ",
        "laUe5LLl7MMe",
        "u8IOTSRz7MMn",
        "01XZhNmj7MMt"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et4CIcCA7MJs",
        "colab_type": "code",
        "outputId": "a8f4b253-e687-4658-9977-93372ef82365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JF8WqYZtjGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow==2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl7vSLrj7MJz",
        "colab_type": "text"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80YEgRgw7MJ1",
        "colab_type": "text"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmfP80h27MJ4",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a27-eSW7MJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YWodM17MKA",
        "colab_type": "text"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9GYLA_j7MKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.dense_1 = Dense(64, activation='relu')\n",
        "    self.dense_2 = Dense(10)\n",
        "    self.dropout = Dropout(0.4)\n",
        "\n",
        "  def call(self, inputs, training=True):\n",
        "    x = self.dense_1(inputs)\n",
        "    if training:\n",
        "      x = self.dropout(x)\n",
        "    return self.dense_2(x)\n",
        "\n",
        "# define a model subclass denoted as MyModel\n",
        "# The objects that you will generate from this class are models with two dense layers. Then within the init method, \n",
        "# you can define the two dense layers.\n",
        "# in the call method, you can set up the forward pass by calling the previously defined dense layers.\n",
        "# Firstly you can place the Dense 1 layer to take the inputs\n",
        "# after it, the Dense 2 layer that returns the outputs of the layer.\n",
        "\n",
        "# Now go back and modify the call method by including a keyword argument called training.\n",
        "# This is useful if you want to have different behavior in training and in inference.\n",
        "# For example, for this, you can create a dropout layer that will be activated only if training is true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvDSeFcA7MKG",
        "colab_type": "code",
        "outputId": "ad92e2ac-af23-4d9c-b4e9-a1a096161c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1,10]))\n",
        "model.summary()\n",
        "\n",
        "# The next step is to instantiate the model. \n",
        "# For this, just call the class without any argument inside the brackets.\n",
        "# Next, call the model on a random input to create the weights.\n",
        "# For the input, I guess using a one-dimensional vector with 10 elements.\n",
        "# After, you can print out model.summary, where you can see the dense layers that you defined before."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  650       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "=================================================================\n",
            "Total params: 1,354\n",
            "Trainable params: 1,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuZ-2O4C-Ble",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.dense_1 = Dense(64, activation='relu')\n",
        "    self.dense_2 = Dense(10)\n",
        "    self.dense_3 = Dense(5)\n",
        "    self.softmax = Softmax()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.dense_1(inputs)\n",
        "    y1 = self.dense_2(inputs)\n",
        "    y2 = self.dense_3(y1)\n",
        "    concat = concatenate([x, y2])\n",
        "    return self.softmax(concat)\n",
        "\n",
        "# you can experiment with concatenating the outputs of two layers.\n",
        "# This is useful if you want to define us obtain non-linear topology in the model.\n",
        "# add a third dense layer of five units together with a softmax layer to the init method.\n",
        "# You can create two branches by playing with the layers in the network.\n",
        "# One branch has only the dense one layer, the other has the dense two, a dense three layers sequentially.\n",
        "# Then the outputs of both branches can be concatenated by just writing concatenate.\n",
        "# At the end, you can set up a softmax layer for the output of the concatenation."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-8wwjfS-no4",
        "colab_type": "code",
        "outputId": "9749a09c-d64d-4f2b-e857-53cb9d02ab12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1,10]))\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  110       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  55        \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            multiple                  0         \n",
            "=================================================================\n",
            "Total params: 869\n",
            "Trainable params: 869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZACFu79n7MKM",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDL5j8na7MKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHffugUp7MKV",
        "colab_type": "text"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocmAGCmB7MKX",
        "colab_type": "code",
        "outputId": "36368528-6a00-45aa-f1bf-89f25fcd6c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape = (input_dim, units),\n",
        "                             initializer = 'random_normal')\n",
        "    self.b = self.add_weight(shape = (units,),\n",
        "                             initializer = 'zeros')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "      return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "dense_layer = MyLayer(3, 5)\n",
        "x = tf.ones((1, 5))\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[1. 1. 1. 1. 1.]], shape=(1, 5), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[ 0.04238772, -0.01499842,  0.03144122],\n",
            "       [-0.00376119,  0.01006788,  0.00616314],\n",
            "       [-0.00847362,  0.03943233, -0.02595833],\n",
            "       [ 0.02076507, -0.05136209,  0.00939988],\n",
            "       [-0.02356167,  0.01731388,  0.08058437]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_yfOoZo7MKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify trainable weights\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape = (input_dim, units),\n",
        "                             initializer = 'random_normal',\n",
        "                             trainable=False)\n",
        "    self.b = self.add_weight(shape = (units,),\n",
        "                             initializer = 'zeros',\n",
        "                             trainable=False)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "      return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "dense_layer = MyLayer(3, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT3kUMzK7MKk",
        "colab_type": "code",
        "outputId": "5a0a9b9f-4f54-4145-d452-f0d2efe049bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: 0\n",
            "non-trainable weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8NU14t17MKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayerMean, self).__init__()\n",
        "    self.w = self.add_weight(shape = (input_dim, units),\n",
        "                             initializer = 'random_normal')\n",
        "    self.b = self.add_weight(shape = (units,),\n",
        "                             initializer = 'zeros')\n",
        "    self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)),\n",
        "                                      trainable=False)\n",
        "    self.number_call = tf.Variable(initial_value=0,\n",
        "                                   trainable=False)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "      activations = tf.matmul(inputs, self.w) + self.b\n",
        "      self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
        "      self.number_call.assign_add(inputs.shape[0])\n",
        "      return activations, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
        "\n",
        "dense_layer = MyLayerMean(3, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbGvIpNv7MKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CeyAa6l7MK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zjah9zC7MK9",
        "colab_type": "text"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72gKLG7k7MK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "\n",
        "        return self.softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgbyBXXg7MLF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "29f8e6e3-001e-4af7-bbd8-9e24f2426cb9"
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[3.8417117e-04 7.0363408e-06 7.0363408e-06 ... 7.0363408e-06\n",
            "  7.0363408e-06 7.0363408e-06]], shape=(1, 10000), dtype=float32)\n",
            "Model: \"my_model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_layer_2 (MyLayer)         multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout (MyDropout)       multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_3 (MyLayer)         multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_1 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_4 (MyLayer)         multiple                  2990      \n",
            "_________________________________________________________________\n",
            "softmax_1 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 0\n",
            "Non-trainable params: 647,214\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLMpvE927MLK",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9U1m1am7MLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V-dWfuU7MLO",
        "colab_type": "text"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-HpHvyu7MLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VETT8KFC7MLY",
        "colab_type": "text"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXlPYKTF7MLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVbYB6nd7MLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omOPHxfJ7MLi",
        "colab_type": "text"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHrAuQY87MLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AXpmrZ-7MLo",
        "colab_type": "text"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jikva3To7MLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLb87KvN7MLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUiBpfzz7MLu",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AXQwWxJ7MLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H29iRg5l7MLx",
        "colab_type": "text"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36CPUq827MLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYAKcqFV7ML1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTleeosW7ML4",
        "colab_type": "text"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7tBL9T_7ML5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLn-j5zn7ML7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTEaudvN7ML8",
        "colab_type": "text"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1LPw8PY7ML9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8fPH-V97ML_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ryLItfi7MMB",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Z5urhf7MMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myUlJq2_7MME",
        "colab_type": "text"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW621La67MMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuk_pQ7A7MMI",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiIpRQDI7MMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCL_MqMc7MML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "    \n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V7P3raP7MMN",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9qkYN8Q7MMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPTrgjWp7MMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oZqFqL17MMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWtoHyZK7MMT",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDMXn_Ae7MMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzeCqC697MMV",
        "colab_type": "text"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZFvutuD7MMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GQvkxOn7MMX",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyBnRa5J7MMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQWvJS8y7MMZ",
        "colab_type": "text"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOkzC3H37MMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize a new model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laUe5LLl7MMe",
        "colab_type": "text"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq21Pxot7MMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8IOTSRz7MMn",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDo3PG2Z7MMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-run the training loop\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01XZhNmj7MMt",
        "colab_type": "text"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaguRKMp7MMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}