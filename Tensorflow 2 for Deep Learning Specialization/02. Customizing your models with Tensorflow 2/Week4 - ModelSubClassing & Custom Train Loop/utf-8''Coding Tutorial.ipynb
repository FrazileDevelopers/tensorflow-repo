{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model subclassing and custom training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Model subclassing](#coding_tutorial_1)\n",
    " #### [2. Custom layers](#coding_tutorial_2)\n",
    " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
    " #### [4. Custom training loops](#coding_tutorial_4)\n",
    " #### [5. tf.function decorator](#coding_tutorial_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Model subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple model using the model subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense_1 = Dense(64, activation='relu')\n",
    "        self.dense_2 = Dense(10)\n",
    "        self.dropout = Dropout(0.4)\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.dense_1(inputs)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        return self.dense_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  704       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  650       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 1,354\n",
      "Trainable params: 1,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model = MyModel()\n",
    "model(tf.random.uniform([1,10]))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.11461521  0.12024755  0.0556697 ]], shape=(1, 3), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
      "array([[-0.05097866,  0.07334182,  0.04024751],\n",
      "       [ 0.0173971 ,  0.09663882,  0.03011249],\n",
      "       [-0.07503157, -0.0129614 , -0.05183677],\n",
      "       [ 0.00480402,  0.02854538,  0.07204843],\n",
      "       [-0.0108061 , -0.06531709, -0.03490196]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Create a custom layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape = (input_dim, units),\n",
    "                             initializer = 'random_normal')\n",
    "        self.b = self.add_weight(shape = (units,),\n",
    "                             initializer = 'zeros')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs,self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3, 5)\n",
    "x = tf.ones((1, 5))\n",
    "print(dense_layer(x))\n",
    "print(dense_layer.weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify trainable weights\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape = (input_dim, units),\n",
    "                             initializer = 'random_normal',\n",
    "                             trainable = False)\n",
    "        self.b = self.add_weight(shape = (units,),\n",
    "                             initializer = 'zeros',\n",
    "                             trainable = False)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs,self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable weights: 0\n",
      "non-trainable weights: 2\n"
     ]
    }
   ],
   "source": [
    "print('trainable weights:', len(dense_layer.trainable_weights))\n",
    "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer to accumulate means of output values\n",
    "class MyLayerMean(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayerMean, self).__init__()\n",
    "        self.w = self.add_weight(shape = (input_dim, units),\n",
    "                             initializer = 'random_normal')\n",
    "        self.b = self.add_weight(shape = (units,),\n",
    "                             initializer = 'zeros')\n",
    "        self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)),\n",
    "                                      trainable=False)\n",
    "        self.number_call = tf.Variable(initial_value=0,\n",
    "                                   trainable=False)\n",
    "    def call(self, inputs):\n",
    "        activations = tf.matmul(inputs, self.w) + self.b\n",
    "        self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
    "        self.number_call.assign_add(inputs.shape[0])\n",
    "        return activations, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
    "    \n",
    "dense_layer=MyLayerMean(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1182289  -0.09689799  0.04159181]\n"
     ]
    }
   ],
   "source": [
    "# Test the layer\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dropout layer as a custom layer\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the custom layers into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using custom layers with the model subclassing API\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2, units_1)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3, units_2)\n",
    "        self.softmax = Softmax()\n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        \n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3d77559566ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate a model object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-33441108d59e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units_1, input_dim_1, units_2, units_3)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Define layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# Instantiate a model object\n",
    "\n",
    "model = MyModel(64,10000,64,46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb0f469a6d8>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create data from a noise contaminated linear model\n",
    "\n",
    "def MakeNoisyData(m, b, n=20):\n",
    "    x = tf.random.uniform(shape=(n,))\n",
    "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
    "    y = m * x + b + noise\n",
    "    return x, y\n",
    "\n",
    "m=1\n",
    "b=2\n",
    "x_train, y_train = MakeNoisyData(m,b)\n",
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.00434499 0.00376688 0.00354343 0.00123178 0.00424324 0.00488142\n",
      " 0.00517764 0.00452184 0.00118957 0.00759797 0.00866501 0.00528125\n",
      " 0.004978   0.00376222 0.00591463 0.00202946 0.00020155 0.00475945\n",
      " 0.00924068 0.00441413], shape=(20,), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.00989882], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Build a custom layer for the linear regression model\n",
    "\n",
    "class LinearLayer(Layer):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.m = self.add_weight(shape=(1,),\n",
    "                             initializer = 'random_normal')\n",
    "        self.b = self.add_weight(shape=(1,),\n",
    "                             initializer = 'zeros')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.m*inputs+self.b\n",
    "\n",
    "linear_regression = LinearLayer()\n",
    "\n",
    "print(linear_regression(x_train))\n",
    "print(linear_regression.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss 6.074968\n"
     ]
    }
   ],
   "source": [
    "# Define the mean squared error loss function\n",
    "\n",
    "def SquaredError(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
    "\n",
    "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
    "print(\"Starting loss\", starting_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 6.074968\n",
      "step 1, loss 4.691066\n",
      "step 2, loss 3.622931\n",
      "step 3, loss 2.798513\n",
      "step 4, loss 2.162203\n",
      "step 5, loss 1.671081\n",
      "step 6, loss 1.292018\n",
      "step 7, loss 0.999447\n",
      "step 8, loss 0.773631\n",
      "step 9, loss 0.599340\n",
      "step 10, loss 0.464817\n",
      "step 11, loss 0.360988\n",
      "step 12, loss 0.280850\n",
      "step 13, loss 0.218996\n",
      "step 14, loss 0.171256\n",
      "step 15, loss 0.134409\n",
      "step 16, loss 0.105968\n",
      "step 17, loss 0.084017\n",
      "step 18, loss 0.067075\n",
      "step 19, loss 0.053998\n",
      "step 20, loss 0.043905\n",
      "step 21, loss 0.036114\n",
      "step 22, loss 0.030101\n",
      "step 23, loss 0.025460\n",
      "step 24, loss 0.021878\n"
     ]
    }
   ],
   "source": [
    "# Implement a gradient descent training loop for the linear regression model\n",
    "learning_rate = 0.05\n",
    "steps = 25\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = linear_regression(x_train)\n",
    "        loss = SquaredError(predictions, y_train)\n",
    "    gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
    "\n",
    "    linear_regression.m.assign_sub(learning_rate*gradients[0])\n",
    "    linear_regression.b.assign_sub(learning_rate*gradients[1])\n",
    "\n",
    "    print('step %d, loss %f' % (i, loss.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:1,  trained m:[0.9243551]\n",
      "b:2,  trained b:[1.9423776]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb0d022cf98>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learned regression model\n",
    "\n",
    "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
    "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
    "\n",
    "plt.plot(x_train, y_train, 'b.')\n",
    "\n",
    "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
    "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## Custom training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom layers and model\n",
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape = (input_dim, units),\n",
    "                             initializer = 'random_normal')\n",
    "        self.b = self.add_weight(shape = (units,),\n",
    "                             initializer = 'zeros')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2, units_1)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3, units_2)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the reuters dataset and define the class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.02142003 0.04403267 0.00859556 0.02055786 0.03461175 0.00603637\n",
      "  0.04944095 0.04392662 0.06284486 0.02813939 0.00749678 0.01220245\n",
      "  0.04599473 0.02108831 0.01721625 0.00707771 0.01357493 0.00353834\n",
      "  0.0164442  0.02748774 0.01909404 0.04637385 0.00940879 0.00365195\n",
      "  0.03227489 0.01203552 0.01727993 0.00563005 0.00772795 0.03429051\n",
      "  0.06374495 0.00917101 0.02388624 0.00965957 0.02625114 0.0210489\n",
      "  0.02570259 0.03028272 0.02163697 0.00293854 0.034156   0.01155385\n",
      "  0.00425614 0.00743616 0.01495189 0.01382834]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer (MyLayer)           multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout (MyDropout)       multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_1 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_1 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_2 (MyLayer)         multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model object\n",
    "model = MyModel(64, 10000, 64, 46)\n",
    "print(model(tf.ones((1,10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape = (input_shape[-1], self.units),\n",
    "                             initializer = 'random_normal',\n",
    "                             name = 'kernel')\n",
    "        self.b = self.add_weight(shape = (self.units,),\n",
    "                             initializer = 'zeros',\n",
    "                             name = 'bias')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.05110761 0.0179624  0.00732059 0.02148862 0.00882861 0.00346547\n",
      "  0.00313879 0.00391534 0.00692865 0.0087078  0.00644566 0.00714823\n",
      "  0.10276317 0.02048427 0.00910049 0.01829344 0.01187979 0.02706901\n",
      "  0.01338513 0.03301912 0.00521868 0.03544619 0.01819213 0.00589729\n",
      "  0.16008784 0.01378222 0.0230991  0.01364988 0.02451459 0.01550546\n",
      "  0.00522879 0.01429631 0.01359653 0.01764958 0.00852835 0.02165365\n",
      "  0.01833434 0.00836734 0.0058822  0.02307842 0.08944128 0.00157\n",
      "  0.01285874 0.01270094 0.00540727 0.04356065]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_3 (MyLayer)         multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_2 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_4 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_3 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_5 (MyLayer)         multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model object\n",
    "model = MyModel(64, 64, 46)\n",
    "print(model(tf.ones((1,10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Print the class of the first sample\n",
    "\n",
    "print(\"Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Reuters word index\n",
    "\n",
    "word_to_index = reuters.get_word_index()\n",
    "\n",
    "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
    "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# Print the first data example sentence\n",
    "\n",
    "print(text_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (8982, 10000)\n",
      "Shape of x_test: (2246, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Define a function that encodes the data into a 'bag of words' representation\n",
    "\n",
    "def bag_of_words(text_samples, elements=10000):\n",
    "    output = np.zeros((len(text_samples), elements))\n",
    "    for i, word in enumerate(text_samples):\n",
    "        output[i, word] = 1.\n",
    "    return output\n",
    "\n",
    "x_train = bag_of_words(train_data)\n",
    "x_test = bag_of_words(test_data)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function and optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical cross entropy loss and Adam optimizer\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def loss(model, x, y, wd):\n",
    "    kernel_variables = []\n",
    "    for l in model.layers:\n",
    "        for w in l.weights:\n",
    "            if 'kernel' in w.name:\n",
    "                kernel_variables.append(w)\n",
    "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
    "    y_ = model(x)\n",
    "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the forward and backward pass\n",
    "\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 000: Loss: 3.307, Accuracy: 47.951%\n",
      "Epoch 001: Loss: 1.904, Accuracy: 61.055%\n",
      "Epoch 002: Loss: 1.823, Accuracy: 65.520%\n",
      "Epoch 003: Loss: 1.776, Accuracy: 67.624%\n",
      "Epoch 004: Loss: 1.740, Accuracy: 68.570%\n",
      "Epoch 005: Loss: 1.740, Accuracy: 68.871%\n",
      "Epoch 006: Loss: 1.730, Accuracy: 69.717%\n",
      "Epoch 007: Loss: 1.706, Accuracy: 69.717%\n",
      "Epoch 008: Loss: 1.700, Accuracy: 70.140%\n",
      "Epoch 009: Loss: 1.697, Accuracy: 70.552%\n",
      "Duration :183.646\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "  # Training loop\n",
    "    for x, y in train_dataset:\n",
    "    # optimize the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # compute current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "    # compare predicted label to actual label\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "\n",
    "  # End Epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                              epoch_loss_avg.result(),\n",
    "                                                              epoch_accuracy.result()))\n",
    "    \n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset object for the test set\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect average loss and accuracy\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight_decay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-52baa918b9ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Optimize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Compute current loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepoch_loss_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weight_decay' is not defined"
     ]
    }
   ],
   "source": [
    "# Loop over the test set and print scores\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value = loss(model, x, y, weight_decay)    \n",
    "    # Compute current loss\n",
    "    epoch_loss_avg(loss_value)  \n",
    "    # Compare predicted label to actual label\n",
    "    epoch_accuracy(to_categorical(y), model(x))\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
    "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss and accuracy\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: earn\n",
      "     Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Get the model prediction for an example input\n",
    "\n",
    "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
    "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
    "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import reuters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new model\n",
    "\n",
    "# Instantiate the model object\n",
    "model = MyModel(64, 64, 46)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefine the grad function using the @tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the @tf.function decorator\n",
    "@tf.function\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 1.669, Accuracy: 70.163%\n",
      "Epoch 001: Loss: 1.667, Accuracy: 70.708%\n",
      "Epoch 002: Loss: 1.661, Accuracy: 71.176%\n",
      "Epoch 003: Loss: 1.670, Accuracy: 71.409%\n",
      "Epoch 004: Loss: 1.679, Accuracy: 71.387%\n",
      "Epoch 005: Loss: 1.668, Accuracy: 71.454%\n",
      "Epoch 006: Loss: 1.670, Accuracy: 71.866%\n",
      "Epoch 007: Loss: 1.664, Accuracy: 71.877%\n",
      "Epoch 008: Loss: 1.655, Accuracy: 71.677%\n",
      "Epoch 009: Loss: 1.673, Accuracy: 72.233%\n",
      "Duration :147.239\n"
     ]
    }
   ],
   "source": [
    "# Re-run the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "  # Training loop\n",
    "    for x, y in train_dataset:\n",
    "    # optimize the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # compute current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "    # compare predicted label to actual label\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "\n",
    "  # End Epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                              epoch_loss_avg.result(),\n",
    "                                                              epoch_accuracy.result()))\n",
    "    \n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the autograph code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__grad(model, inputs, targets, wd):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('grad', 'grad_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as grad_scope:\n",
      "    with tf.GradientTape() as tape:\n",
      "      loss_value = ag__.converted_call(loss, grad_scope.callopts, (model, inputs, targets, wd), None, grad_scope)\n",
      "    do_return = True\n",
      "    retval_ = grad_scope.mark_return_value((loss_value, ag__.converted_call(tape.gradient, grad_scope.callopts, (loss_value, model.trainable_variables), None, grad_scope)))\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf.autograph.to_code to see the generated code\n",
    "\n",
    "print(tf.autograph.to_code(grad.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
